{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "from shutil import copyfile\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import json\n",
    "import copy\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH_DATA = 'data/skogsstyrelsen/'\n",
    "BAND_NAMES = ['b01', 'b02', 'b03', 'b04', 'b05', 'b06', 'b07', 'b08', 'b8a', 'b09', 'b11', 'b12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data + corresponding json info (incl ground truth)\n",
    "img_paths_train = list(np.load(os.path.join(BASE_PATH_DATA, 'skogs_names_train.npy')))\n",
    "img_paths_train = [path[1:] for path in img_paths_train]\n",
    "\n",
    "img_paths_val = list(np.load(os.path.join(BASE_PATH_DATA, 'skogs_names_val.npy')))\n",
    "img_paths_val = [path[1:] for path in img_paths_val]\n",
    "\n",
    "img_paths_test = list(np.load(os.path.join(BASE_PATH_DATA, 'skogs_names_test.npy')))\n",
    "img_paths_test = [path[1:] for path in img_paths_test]\n",
    "\n",
    "json_content_train = list(np.load(os.path.join(BASE_PATH_DATA, 'skogs_json_train.npy'), allow_pickle=True))\n",
    "json_content_val = list(np.load(os.path.join(BASE_PATH_DATA, 'skogs_json_val.npy'), allow_pickle=True))\n",
    "json_content_test = list(np.load(os.path.join(BASE_PATH_DATA, 'skogs_json_test.npy'), allow_pickle=True))\n",
    "\n",
    "train_label = list(np.load(os.path.join(BASE_PATH_DATA, \"skogs_gts_train.npy\")))\n",
    "val_label = list(np.load(os.path.join(BASE_PATH_DATA, \"skogs_gts_val.npy\")))\n",
    "test_label = list(np.load(os.path.join(BASE_PATH_DATA, \"skogs_gts_test.npy\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'train size = {len(img_paths_train)}')\n",
    "print(f'val size = {len(img_paths_val)}')\n",
    "print(f'test size = {len(img_paths_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot distribution of each data set\n",
    "labels = [\"clear\", \"cloudy\"]\n",
    "labels_num = [0,1]\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3, figsize=(10,5))\n",
    "\n",
    "# Bar for training\n",
    "cloudy = np.count_nonzero(train_label)\n",
    "clear = len(train_label) - cloudy\n",
    "ax1.bar(labels_num, [clear,cloudy])\n",
    "ax1.set_xticks(labels_num, labels)\n",
    "ax1.set_title(\"Distribution of training set\")\n",
    "ylim = ax1.get_ylim()\n",
    "\n",
    "# Bar for validation\n",
    "cloudy = np.count_nonzero(val_label)\n",
    "clear = len(val_label) - cloudy\n",
    "ax2.bar(labels_num, [clear,cloudy])\n",
    "ax2.set_xticks(labels_num, labels)\n",
    "ax2.set_title(\"Distribution of validation set\")\n",
    "ax2.set_ylim(ylim)\n",
    "\n",
    "# Bar for testing\n",
    "cloudy = np.count_nonzero(test_label)\n",
    "clear = len(test_label) - cloudy\n",
    "ax3.bar(labels_num, [clear,cloudy])\n",
    "ax3.set_xticks(labels_num, labels)\n",
    "ax3.set_title(\"Distribution of test set\")\n",
    "ax3.set_ylim(ylim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    img = xr.open_dataset(path)\n",
    "    yy_mm_dd = getattr(img, 'time').values[0]\n",
    "    yy = yy_mm_dd.astype('datetime64[Y]').astype(int) + 1970\n",
    "    mm = yy_mm_dd.astype('datetime64[M]').astype(int) % 12 + 1\n",
    "\n",
    "    band_list = []\n",
    "    for band in BAND_NAMES:\n",
    "        if yy >= 2022 and mm >= 1: # New normalization after Jan 2022\n",
    "            band_list.append((getattr(img, band).values - 1000) / 10000)\n",
    "        else:\n",
    "            band_list.append(getattr(img, band).values / 10000) \n",
    "            \n",
    "    img = np.concatenate(band_list, axis = 0)\n",
    "    img = np.transpose(img, [1,2,0])\n",
    "    img = np.fliplr(img).copy()\n",
    "    img = np.flipud(img).copy()\n",
    "\n",
    "    H, W = img.shape[:2]\n",
    "    \n",
    "    # padding\n",
    "    if H != 21 and W != 21:\n",
    "        zeros = np.zeros((1, 20, 12))\n",
    "        img = np.concatenate((img, zeros), axis = 0)\n",
    "        zeros = np.zeros((21, 1, 12))\n",
    "        img = np.concatenate((img, zeros[:]), axis = 1)\n",
    "        \n",
    "    elif H != 21:\n",
    "        zeros = np.zeros((1, 21, 12))\n",
    "        img = np.concatenate((img, zeros), axis = 0)\n",
    "        \n",
    "    elif W != 21:\n",
    "        zeros = np.zeros((21, 1, 12))\n",
    "        img = np.concatenate((img, zeros[:]), axis = 1)\n",
    "        \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incase we want to use a Dataloader, we could use this\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, label_dir, img_dir, transform=None, target_transform=None):\n",
    "        self.img_labels = list(np.load(label_dir))\n",
    "        self.img_dir = img_dir\n",
    "        image_paths = list(np.load(img_dir))\n",
    "        self.image_paths = [path[1:] for path in image_paths]\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = load_image(self.image_paths[idx])\n",
    "        label = self.img_labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 10\n",
    "SHUFFLE = False\n",
    "\n",
    "train_data = CustomImageDataset(os.path.join(BASE_PATH_DATA, \"skogs_gts_train.npy\"), os.path.join(BASE_PATH_DATA, 'skogs_names_train.npy'), transform=transforms.ToTensor())\n",
    "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=SHUFFLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# showing the first batch when using tensors\n",
    "def show_batch(dl): \n",
    "    for images,lables in dl: \n",
    "        rgb_img = images[:, [3,2,1], :, :]/torch.max(images[:, [3,2,1], :, :])\n",
    "        list_img = [img for img in rgb_img]\n",
    "        Grid = make_grid(list_img, nrow=5)\n",
    "        img = transforms.ToPILImage()(Grid) \n",
    "        img.show() \n",
    "        break\n",
    "        \n",
    "# show first batch of train data\n",
    "show_batch(train_loader)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
